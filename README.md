# Neural-Network-Compression-and-Accelerator-on-Hardware

My name is Fang Biao. I'm currently pursuing my Master degree with the college of Computer Science and Engineering, Si Chuan University, Cheng Du, China. For more informantion about me and my research, you can go to [my homepage](https://github.com/hisrg). One of my research interests is architecture design for deep learning and neuromorphic computing. This is an exciting field where fresh ideas come out every day, so I'm collecting works on related topics. Welcome to join us!


中文：我叫房彪，目曾职于Qualcomm Shanghai(SDC),曾就读于计算学院，四川大学. 关于我目前的研究内容您可以登陆github.com/hisrg进行浏览，我目前研究的主要内容是基于深度学习和类脑计算的系统架构，这是一个非常振奋人心的领域，因此我一直在收集相关领域的最新工作，欢迎加入我们！

## Table of Contents
 - [My Contributions](#my-contributions)
 - [Paper List](#conference-papers)

## My Contributions
- [An FPGA Implementation of Deep Spiking Neural Network for Low-Power and Fast Classification.](Xiping Ju, Biao Fang, Rui Yan, Xiaoliang Xu, & Huajin Tang. (2019).)(http://www.ncbi.nlm.nih.gov/pubmed/31703174)(Neural Computation. (Published))
- [Spike Trains Encoding Optimization for Spiking Neural Networks Implementation in FPGA.](Fang B, Zhang Y, Yan R, Tang H.(2020))(2020 12th International Conference on Advanced Computational Intelligence (ICACI), IEEE, 2020, pp. 412-418.Published)

## Paper List
| 英文题目 | 中文题目 | 状态 |
| :-----| ----: | :----: |
| A Comprehensive Survey on Hardware-Aware Neural Architecture Search | 硬件感知神经网络架构搜索方法综述 | 翻译中 |
| EFFICIENT METHODS AND HARDWARE FOR DEEP LEARNING-augmented hangsong's PhD denfense | 韩松博士毕业论文：深度学习有效硬件加速与算法 | 已上传 |
|Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference|神经网络算法有整型效量化与训练|已上传|
|Speeding up Convolutional Neural Networks with Low Rank Expansions|地址分解提速神经网络|已上传|
|A Survey of Model Compression and Acceleration for Deep Neural Networks|/关于深度神经网络模型压缩与加速方面的调查|已上传|
## 联系方式
afetsc2008@sina.com
